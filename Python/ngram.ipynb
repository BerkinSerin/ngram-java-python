{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "# dictionaries for n-grams\n",
    "unidict = {}\n",
    "bidict = {}\n",
    "tridict = {}\n",
    "\n",
    "# regexes to match ?.. !.. and other repeating chars such as ...    \n",
    "regexes = [\n",
    "    r'[?!]?[.]+',\n",
    "    r'[«?{(].{1}[»?})]',\n",
    "    r'[^a-zA-Z0-9güsâöiçIÂGÜSÖÇ]'\n",
    "]\n",
    "\n",
    "# combine regexes into one ultimate regex\n",
    "combined = \"(\" + \")|(\".join(regexes) + \")\"\n",
    "\n",
    "# function to get the final version of the given string \n",
    "def getFinalString (path):\n",
    "    # read the file and join the paragraphs into one string\n",
    "    corpus = open(path, encoding='ISO-8859-9').read()\n",
    "    corpus = corpus.replace('\\r', ' ')\n",
    "    corpus = corpus.replace('\\n', ' ').strip()\n",
    "    \n",
    "    \n",
    "    # seperate punctuations and special characters (!.. ?.. (?) ......)\n",
    "    \n",
    "    corpus = re.sub(combined,' \\g<0> ', corpus) #this will match the first regex it matches on the string \n",
    "    corpus = re.sub(' +', ' ', corpus)\n",
    "    return corpus\n",
    "\n",
    "# paths for the documents and a list to keep them all\n",
    "paths = []\n",
    "path1 = \"C:/Users/berki/Desktop/nlp_1/BILIM IS BASINDA.txt\"\n",
    "path2 = \"C:/Users/berki/Desktop/nlp_1/BOZKIRDA.txt\"\n",
    "path3 = \"C:/Users/berki/Desktop/nlp_1/DEGISIM.txt\"\n",
    "path4 = \"C:/Users/berki/Desktop/nlp_1/DENEMELER.txt\"\n",
    "path5 = \"C:/Users/berki/Desktop/nlp_1/UNUTULMUS DIYARLAR.txt\"\n",
    "\n",
    "paths.append(path1)\n",
    "paths.append(path2)\n",
    "paths.append(path3)\n",
    "paths.append(path4)\n",
    "paths.append(path5)\n",
    "\n",
    "# corpus to generate n-grams from\n",
    "corpus = ''\n",
    "\n",
    "# create ultimate final corpus (append each document to the corpus)\n",
    "for path in paths:\n",
    "    corpus = corpus + ' ' + getFinalString(path)\n",
    "    corpus = corpus.strip()\n",
    "    \n",
    "# function for ngrams\n",
    "def get_ngrams(wordlist,n):\n",
    "    wordlist = [x.lower() for x in wordlist]\n",
    "    wordlist = [x.replace(' +', ' ') for x in wordlist]\n",
    "    ngrams = {}\n",
    "    for i in range(len(wordlist)-(n-1)):\n",
    "        if ' '.join(wordlist[i:i+n]) in ngrams:\n",
    "            ngrams[' '.join(wordlist[i:i+n])] += 1\n",
    "        else:\n",
    "            ngrams[' '.join(wordlist[i:i+n])] = 1\n",
    "            \n",
    "    return sorted(ngrams.items(), key=lambda x: x[1], reverse=True)[:100] # sort them descending and return top 100\n",
    "\n",
    "unidict = get_ngrams(corpus.split(' '), 1)\n",
    "bidict = get_ngrams(corpus.split(' '), 2)\n",
    "tridict = get_ngrams(corpus.split(' '), 3)\n",
    "\n",
    "print('Top 100 1-grams for the corpus: \\n')\n",
    "print(unidict)\n",
    "print('\\n')\n",
    "print('Top 100 2-grams for the corpus: \\n')\n",
    "print(bidict)\n",
    "print('\\n')\n",
    "print('Top 100 3-grams for the corpus: \\n')\n",
    "print(tridict)\n",
    "print('\\n')\n",
    "end = time.time()\n",
    "print('Runtime in milliseconds: {0}'.format(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
